"use strict";(self.webpackChunkastria_docs_2=self.webpackChunkastria_docs_2||[]).push([[4653],{3905:(e,t,i)=>{i.d(t,{Zo:()=>u,kt:()=>d});var n=i(7294);function r(e,t,i){return t in e?Object.defineProperty(e,t,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[t]=i,e}function a(e,t){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),i.push.apply(i,n)}return i}function o(e){for(var t=1;t<arguments.length;t++){var i=null!=arguments[t]?arguments[t]:{};t%2?a(Object(i),!0).forEach((function(t){r(e,t,i[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):a(Object(i)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(i,t))}))}return e}function s(e,t){if(null==e)return{};var i,n,r=function(e,t){if(null==e)return{};var i,n,r={},a=Object.keys(e);for(n=0;n<a.length;n++)i=a[n],t.indexOf(i)>=0||(r[i]=e[i]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)i=a[n],t.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(e,i)&&(r[i]=e[i])}return r}var l=n.createContext({}),p=function(e){var t=n.useContext(l),i=t;return e&&(i="function"==typeof e?e(t):o(o({},t),e)),i},u=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},g="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var i=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),g=p(i),c=r,d=g["".concat(l,".").concat(c)]||g[c]||m[c]||a;return i?n.createElement(d,o(o({ref:t},u),{},{components:i})):n.createElement(d,o({ref:t},u))}));function d(e,t){var i=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=i.length,o=new Array(a);o[0]=c;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[g]="string"==typeof e?e:r,o[1]=s;for(var p=2;p<a;p++)o[p]=i[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,i)}c.displayName="MDXCreateElement"},7687:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>u,contentTitle:()=>l,default:()=>d,frontMatter:()=>s,metadata:()=>p,toc:()=>g});var n=i(7462),r=(i(7294),i(3905));const a=i.p+"assets/images/ai-photoshoot-output-79da8a3cef6fc255171431261d38c892.jpg";var o=i(118);const s={tags:["flux","training","fine-tuning","lora"],image:"./img/ai-photoshoot-output.jpg"},l="Flux training",p={unversionedId:"use-cases/flux-finetuning",id:"use-cases/flux-finetuning",title:"Flux training",description:"Overview",source:"@site/docs/use-cases/05-flux-finetuning.md",sourceDirName:"use-cases",slug:"/use-cases/flux-finetuning",permalink:"/docs/use-cases/flux-finetuning",draft:!1,tags:[{label:"flux",permalink:"/docs/tags/flux"},{label:"training",permalink:"/docs/tags/training"},{label:"fine-tuning",permalink:"/docs/tags/fine-tuning"},{label:"lora",permalink:"/docs/tags/lora"}],version:"current",sidebarPosition:5,frontMatter:{tags:["flux","training","fine-tuning","lora"],image:"./img/ai-photoshoot-output.jpg"},sidebar:"tutorialSidebar",previous:{title:"Fine-tuning guide",permalink:"/docs/use-cases/finetuning-guide"},next:{title:"SDXL training",permalink:"/docs/use-cases/sdxl-training"}},u={image:i(670).Z},g=[{value:"Overview",id:"overview",level:2},{value:"Training presets",id:"training-presets",level:2},{value:"Training tips",id:"training-tips",level:2},{value:"Inference tips",id:"inference-tips",level:2},{value:"API usage",id:"api-usage",level:2}],m={toc:g},c="wrapper";function d(e){let{components:t,...s}=e;return(0,r.kt)(c,(0,n.Z)({},m,s,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"flux-training"},"Flux training"),(0,r.kt)("h2",{id:"overview"},"Overview"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Flux")," is a family of generative image models created by ",(0,r.kt)("a",{parentName:"p",href:"https://blackforestlabs.ai/announcing-black-forest-labs/"},"Black Forest Labs")," making use of some of the latest AI advancement such as diffusion, transformer (MMDiT), Flow-matching and a large T5 text encoder. "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"The large text encoder allows the text2img model to better align the image with the given prompt and create complex images with a single prompt. ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"The model base resolution is 1024x1024 however unlike previous models, was trained on a variety of aspect ratios its neural-network architecture is able to better cope with different aspect ratios both in training and inference.  ")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Flux1.dev requires commercial licensing which is provided to Astria customers."))),(0,r.kt)("div",{style:{display:"grid","grid-template-columns":"1fr 1fr",gap:"1.5rem"}},(0,r.kt)("div",null,"Input training images",(0,r.kt)("img",{src:o.Z,alt:"generated.png"})),(0,r.kt)("div",null,"Output images",(0,r.kt)("img",{src:a,alt:"generated.png"}))),(0,r.kt)("h2",{id:"training-presets"},"Training presets"),(0,r.kt)("p",null,"Astria uses training presets to evolve its training strategies and provide better results while also providing a stable API for its customers."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"Our current recommendation is to use the ",(0,r.kt)("inlineCode",{parentName:"p"},"portrait")," preset for training Flux models.")),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Focus")," - API ",(0,r.kt)("inlineCode",{parentName:"li"},"flux-lora-focus")," - Focus preset automatically balances different types of training, allowing it to focus on faces, products as well as styles."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Portrait")," - API ",(0,r.kt)("inlineCode",{parentName:"li"},"flux-lora-portrait")," - This preset is generally recommended for any kind of training including non portraits, except for ",(0,r.kt)("inlineCode",{parentName:"li"},"style")," training. With the latest ",(0,r.kt)("inlineCode",{parentName:"li"},"portrait")," we now use more precise hyper-parameters for training, improved pre-processing, better handling of blurred/low-res images, face-cropping and focusing on learning face features, less overfitting to clothing and background. You will get more diverse images with better prompt alignment while better preserving identity and face. For this preset we default to 27 steps per image for training, with minimum steps of 300. You may override the number of steps depending on price and quality requirements."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Fast")," API ",(0,r.kt)("inlineCode",{parentName:"li"},"flux-lora-fast")," - Legacy preset. Provides an alternative for the high preset, with faster training and lower cost. Similarly to the ",(0,r.kt)("inlineCode",{parentName:"li"},"portrait")," preset, it uses 27 steps per image for training, with minimum steps of 300. "),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"High")," API ",(0,r.kt)("inlineCode",{parentName:"li"},"null")," - High steps, low-learning rate. Should be used for ",(0,r.kt)("inlineCode",{parentName:"li"},"style")," training or training sets with 20+ images. With the high preset, we default to 100 steps per image for training, with minimum steps of 300. You may override the number of steps depending on price and quality requirements.")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Training preset screenshot in new fine-tune",src:i(5719).Z,width:"1532",height:"1310"})),(0,r.kt)("h2",{id:"training-tips"},"Training tips"),(0,r.kt)("p",null,"Default token for SDXL should be ",(0,r.kt)("inlineCode",{parentName:"p"},"ohwx")," and will be set automatically if none is specified"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"As with other models, a good training set is critical to getting great results. See ",(0,r.kt)("a",{parentName:"li",href:"/docs/use-cases/ai-photoshoot/"},"AI photoshoot guide")),(0,r.kt)("li",{parentName:"ol"},"Astria currently defaults to 100 steps per image for training a Flux lora for the high preset, and 27 steps per image for the fast preset. Fast preset is recommended when training on people or headshots. "),(0,r.kt)("li",{parentName:"ol"},"You may opt to override the number of training steps in order to reduce costs and processing time. Reducing the steps can produce good results when the target inference images are similar to the input training images (like headshots). Example lower steps could be 600, 1000 or 1200 (roughly 50-70 * number of training images )")),(0,r.kt)("h2",{id:"inference-tips"},"Inference tips"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Dense prompts")," - Flux works best when the prompt is descriptive and detailed, but as in most models, be concise. Overdoing the description can create conflicts in the inference."),(0,r.kt)("li",{parentName:"ol"},"*",(0,r.kt)("em",{parentName:"li"},"No negatives")," - Flux doesn\u2019t work with negatives, instead we suggest using positive prompts. For example, instead of writing \u2018cartoon\u2019 in the negative, write \u2018realistic settings and characters\u2019 in the prompt.  "),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"No weighted prompts")," - using weights or parentheses () to emphasis certain parts of a prompt doesn\u2019t work with Flux. Instead, make sure the important parts at the beginning of the prompt."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Adding text in the image")," - One of the advantages of Flux is the ability to add text to an image. There are a few ways to do that, like \u201cohwx man holding a sign with the words \u2018Hello\u2019\u201c."),(0,r.kt)("li",{parentName:"ol"},"Looking for prompt ideas? Try the ",(0,r.kt)("a",{parentName:"li",href:"https://www.astria.ai/themes"},"Themes")," feature. Themes uses Claude GPT to help write prompts for the specific model. You can add a theme and write any topic on your mind, and themes will produce 10 prompts on it.")),(0,r.kt)("h2",{id:"api-usage"},"API usage"),(0,r.kt)("p",null,"See here for ",(0,r.kt)("a",{parentName:"p",href:"/docs/api/flux-api"},"API usage")))}d.isMDXComponent=!0},118:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/ai-photoshoot-input-66e224267554a6902bfaa5e6103ae27f.jpg"},670:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/ai-photoshoot-output-79da8a3cef6fc255171431261d38c892.jpg"},5719:(e,t,i)=>{i.d(t,{Z:()=>n});const n=i.p+"assets/images/new-finetune-presets-53c9a515f3bddb36bbac49aaa00141bb.png"}}]);