"use strict";(self.webpackChunkastria_docs_2=self.webpackChunkastria_docs_2||[]).push([[5593],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>g});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=p(n),m=i,g=u["".concat(l,".").concat(m)]||u[m]||d[m]||r;return n?a.createElement(g,o(o({ref:t},c),{},{components:n})):a.createElement(g,o({ref:t},c))}));function g(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:i,o[1]=s;for(var p=2;p<r;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},3749:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>p});var a=n(7462),i=(n(7294),n(3905));const r={},o="SDXL training",s={unversionedId:"use-cases/sdxl-training",id:"use-cases/sdxl-training",title:"SDXL training",description:"Overview",source:"@site/docs/use-cases/sdxl-training.md",sourceDirName:"use-cases",slug:"/use-cases/sdxl-training",permalink:"/docs/use-cases/sdxl-training",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/use-cases/sdxl-training.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Product shots",permalink:"/docs/use-cases/product-shots"},next:{title:"Fine-tuning guide",permalink:"/docs/use-cases/the-guide-for-high-quality-avatars"}},l={},p=[{value:"Overview",id:"overview",level:2},{value:"Training tips",id:"training-tips",level:2},{value:"Inference tips",id:"inference-tips",level:2},{value:"Aspect-ratios",id:"aspect-ratios",level:2},{value:"API tips",id:"api-tips",level:2}],c={toc:p},u="wrapper";function d(e){let{components:t,...r}=e;return(0,i.kt)(u,(0,a.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"sdxl-training"},"SDXL training"),(0,i.kt)("h2",{id:"overview"},"Overview"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Stable Diffusion XL")," or ",(0,i.kt)("strong",{parentName:"p"},"SDXL")," is the latest image generation model that is tailored towards more photorealistic outputs with more detailed imagery and composition. SDXL can generate realistic faces, legible text within the images, and better image composition, all while using shorter and simpler prompts."),(0,i.kt)("admonition",{type:"info"},(0,i.kt)("p",{parentName:"admonition"},(0,i.kt)("inlineCode",{parentName:"p"},"LoRA + Text-embedding")," is currently the only option for fine-tuning SDXL.")),(0,i.kt)("div",{style:{display:"grid","grid-template-columns":"1fr 1fr",gap:"1.5rem"}},(0,i.kt)("div",null,"Input training images",(0,i.kt)("p",null,(0,i.kt)("img",{alt:"source.png",src:n(3957).Z,width:"2000",height:"2203"}))),(0,i.kt)("div",null,(0,i.kt)("p",null,"Output images"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"generated.png",src:n(9970).Z,width:"670",height:"893"})))),(0,i.kt)("h2",{id:"training-tips"},"Training tips"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Default token for SDXL should be ",(0,i.kt)("inlineCode",{parentName:"li"},"ohwx")," and will be set automatically if none is specified"),(0,i.kt)("li",{parentName:"ol"},"Training resolution is - make sure training images are at least 1024x1024px")),(0,i.kt)("h2",{id:"inference-tips"},"Inference tips"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Activate face-inpainting (which in turn requires super-resolution) - this is the biggest boost you can get to increase similarity to subject"),(0,i.kt)("li",{parentName:"ol"},"Use ",(0,i.kt)("inlineCode",{parentName:"li"},"euler_a")," scheduler"),(0,i.kt)("li",{parentName:"ol"},"Do not copy and paste prompts from SD15"),(0,i.kt)("li",{parentName:"ol"},"Use clean small concise prompts - usually up to 15 words"),(0,i.kt)("li",{parentName:"ol"},"Avoid long negatives."),(0,i.kt)("li",{parentName:"ol"},"Do not use textual-inversions such as ",(0,i.kt)("inlineCode",{parentName:"li"},"easynegative")," or ",(0,i.kt)("inlineCode",{parentName:"li"},"badhands")," from SD15"),(0,i.kt)("li",{parentName:"ol"},"Start with baseline SDXL 1.0 inference before going to other base models. Most custom SDXL Civit model available are very biased and may reduce similarity. Models which we noticed that work okay are ",(0,i.kt)("inlineCode",{parentName:"li"},"ZavyChromaXL")," and ",(0,i.kt)("inlineCode",{parentName:"li"},"ClearChromaXL"))),(0,i.kt)("h2",{id:"aspect-ratios"},"Aspect-ratios"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-text"},"0.5: 704, 1408\n0.52: 704, 1344\n0.57: 768, 1344\n0.6: 768, 1280\n0.68: 832, 1216\n0.72: 832, 1152\n0.78: 896, 1152\n0.82: 896, 1088\n0.88: 960, 1088\n0.94: 960, 1024\n1.0: 1024, 1024\n1.07: 1024, 960\n1.13: 1088, 960\n1.21: 1088, 896\n1.29: 1152, 896\n1.38: 1152, 832\n1.46: 1216, 832\n1.67: 1280, 768\n1.75: 1344, 768\n1.91: 1344, 704\n2.0: 1408, 704\n2.09: 1472, 704\n2.4: 1536, 640\n2.5: 1600, 640\n2.89: 1664, 576\n3.0: 1728, 576\n")),(0,i.kt)("p",null,"All above tips will help increase similarity to the original subject."),(0,i.kt)("h2",{id:"api-tips"},"API tips"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Unlike SD15 checkpoint training, SDXL on Astria is trained as a LoRa+text-embedding. As such, inference is taking place a on a base line model such as SDXL 1.0 and ",(0,i.kt)("inlineCode",{parentName:"li"},"prompt.text")," should specify the loaded lora such as ",(0,i.kt)("inlineCode",{parentName:"li"},"<lora:123456:0.83>")," - will load lora with id=123456 and strength=0.83"),(0,i.kt)("li",{parentName:"ol"},"Inference API can call `",(0,i.kt)("inlineCode",{parentName:"li"},"POST [https://api.astria.ai/prompts](https://www.astria.ai/prompts)")," with ",(0,i.kt)("inlineCode",{parentName:"li"},"tune_id=666678"),"or ",(0,i.kt)("a",{parentName:"li",href:"https://www.astria.ai/prompts"},(0,i.kt)("inlineCode",{parentName:"a"},"https://api.astria.ai/tunes/666678/prompts"))),(0,i.kt)("li",{parentName:"ol"},"See ",(0,i.kt)("a",{parentName:"li",href:"/docs/features/loras"},"LoRa docs")," on lora syntax"),(0,i.kt)("li",{parentName:"ol"},"Note that you cannot combine or load multiple LoRa+Text-embedding in one prompt, unlike regular LoRa")))}d.isMDXComponent=!0},3957:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/ai-photoshoot-input-3e9da4e3f5e050cbe4f36788a62521de.png"},9970:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/sdxl-output-eb2fc7f16279a8316300344ad7b0d084.jpeg"}}]);