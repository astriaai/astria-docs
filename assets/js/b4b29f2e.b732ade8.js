"use strict";(self.webpackChunkastria_docs_2=self.webpackChunkastria_docs_2||[]).push([[4653],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>d});var i=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},r=Object.keys(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=i.createContext({}),p=function(e){var t=i.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},u=function(e){var t=p(e.components);return i.createElement(l.Provider,{value:t},e.children)},c="mdxType",g={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},m=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=p(n),m=a,d=c["".concat(l,".").concat(m)]||c[m]||g[m]||r;return n?i.createElement(d,o(o({ref:t},u),{},{components:n})):i.createElement(d,o({ref:t},u))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,o=new Array(r);o[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:a,o[1]=s;for(var p=2;p<r;p++)o[p]=n[p];return i.createElement.apply(null,o)}return i.createElement.apply(null,n)}m.displayName="MDXCreateElement"},7687:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>u,contentTitle:()=>l,default:()=>d,frontMatter:()=>s,metadata:()=>p,toc:()=>c});var i=n(7462),a=(n(7294),n(3905));const r=n.p+"assets/images/ai-photoshoot-output-79da8a3cef6fc255171431261d38c892.jpg";var o=n(118);const s={tags:["flux","training","fine-tuning","lora"]},l="Flux training",p={unversionedId:"use-cases/flux-finetuning",id:"use-cases/flux-finetuning",title:"Flux training",description:"Overview",source:"@site/docs/use-cases/05-flux-finetuning.md",sourceDirName:"use-cases",slug:"/use-cases/flux-finetuning",permalink:"/docs/use-cases/flux-finetuning",draft:!1,tags:[{label:"flux",permalink:"/docs/tags/flux"},{label:"training",permalink:"/docs/tags/training"},{label:"fine-tuning",permalink:"/docs/tags/fine-tuning"},{label:"lora",permalink:"/docs/tags/lora"}],version:"current",sidebarPosition:5,frontMatter:{tags:["flux","training","fine-tuning","lora"]},sidebar:"tutorialSidebar",previous:{title:"Fine-tuning guide",permalink:"/docs/use-cases/finetuning-guide"},next:{title:"SDXL training",permalink:"/docs/use-cases/sdxl-training"}},u={},c=[{value:"Overview",id:"overview",level:2},{value:"Training tips",id:"training-tips",level:2},{value:"Inference tips",id:"inference-tips",level:2},{value:"API usage",id:"api-usage",level:2}],g={toc:c},m="wrapper";function d(e){let{components:t,...n}=e;return(0,a.kt)(m,(0,i.Z)({},g,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"flux-training"},"Flux training"),(0,a.kt)("h2",{id:"overview"},"Overview"),(0,a.kt)("p",null,(0,a.kt)("em",{parentName:"p"},"Flux")," is a family of generative image models created by ",(0,a.kt)("a",{parentName:"p",href:"https://blackforestlabs.ai/announcing-black-forest-labs/"},"Black Forest Labs")," making use of some of the latest AI advancement such as diffusion, transformer (MMDiT), Flow-matching and a large T5 text encoder. "),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"The large text encoder allows the text2img model to better align the image with the given prompt and create complex images with a single prompt. ")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"The model base resolution is 1024x1024 however unlike previous models, was trained on a variety of aspect ratios its neural-network architecture is able to better cope with different aspect ratios both in training and inference.  ")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Flux1.dev requires commercial licensing which is provided to Astria customers."))),(0,a.kt)("div",{style:{display:"grid","grid-template-columns":"1fr 1fr",gap:"1.5rem"}},(0,a.kt)("div",null,"Input training images",(0,a.kt)("img",{src:o.Z,alt:"generated.png"})),(0,a.kt)("div",null,"Output images",(0,a.kt)("img",{src:r,alt:"generated.png",style:{height:500}}))),(0,a.kt)("h2",{id:"training-tips"},"Training tips"),(0,a.kt)("p",null,"Default token for SDXL should be ",(0,a.kt)("inlineCode",{parentName:"p"},"ohwx")," and will be set automatically if none is specified"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"As with other models, a good training set is critical to getting great results. See ",(0,a.kt)("a",{parentName:"li",href:"/docs/use-cases/ai-photoshoot/"},"AI photoshoot guide")),(0,a.kt)("li",{parentName:"ol"},"Flux training is expensive comparing to previous (see ",(0,a.kt)("a",{parentName:"li",href:"https://www.astria.ai/pricing"},"pricing"),") and slow. "),(0,a.kt)("li",{parentName:"ol"},"Astria currently defaults to 100 steps per image for training a Flux lora. "),(0,a.kt)("li",{parentName:"ol"},"You may opt to override the number of training steps in order to reduce costs and processing time. Reducing the steps can produce good results when the target inference images are similar to the input training images (like headshots). Example lower steps could be 600, 1000 or 1200 (roughly 50-70 * number of training images )")),(0,a.kt)("h2",{id:"inference-tips"},"Inference tips"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Dense prompts")," - Flux works best when the prompt is descriptive and detailed, but as in most models, be concise. Overdoing the description can create conflicts in the inference."),(0,a.kt)("li",{parentName:"ol"},"*",(0,a.kt)("em",{parentName:"li"},"No negatives")," - Flux doesn\u2019t work with negatives, instead we suggest using positive prompts. For example, instead of writing \u2018cartoon\u2019 in the negative, write \u2018realistic settings and characters\u2019 in the prompt.  "),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"No weighted prompts")," - using weights or parentheses () to emphasis certain parts of a prompt doesn\u2019t work with Flux. Instead, make sure the important parts at the beginning of the prompt."),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Adding text in the image")," - One of the advantages of Flux is the ability to add text to an image. There are a few ways to do that, like \u201cohwx man holding a sign with the words \u2018Hello\u2019\u201c."),(0,a.kt)("li",{parentName:"ol"},"Looking for prompt ideas? Try the ",(0,a.kt)("a",{parentName:"li",href:"https://www.astria.ai/themes"},"Themes")," feature. Themes uses Claude GPT to help write prompts for the specific model. You can add a theme and write any topic on your mind, and themes will produce 10 prompts on it.")),(0,a.kt)("h2",{id:"api-usage"},"API usage"),(0,a.kt)("p",null,"See here for ",(0,a.kt)("a",{parentName:"p",href:"/docs/api/flux-api"},"API usage")))}d.isMDXComponent=!0},118:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/ai-photoshoot-input-66e224267554a6902bfaa5e6103ae27f.jpg"}}]);